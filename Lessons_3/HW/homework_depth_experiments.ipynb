{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0716b4f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error downloading train-images-idx3-ubyte.gz:\nTried https://ossci-datasets.s3.amazonaws.com/mnist/, got:\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>\nTried http://yann.lecun.com/exdb/mnist/, got:\nHTTP Error 404: Not Found\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_training_history\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Получаем данные MNIST\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m train_loader, test_loader = \u001b[43mget_mnist_loaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Список конфигураций для разных моделей\u001b[39;00m\n\u001b[32m     11\u001b[39m configs = [\n\u001b[32m     12\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mlayers\u001b[39m\u001b[33m\"\u001b[39m: [{\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m10\u001b[39m}]},  \u001b[38;5;66;03m# 1 слой\u001b[39;00m\n\u001b[32m     13\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mlayers\u001b[39m\u001b[33m\"\u001b[39m: [{\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m512\u001b[39m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m10\u001b[39m}]},  \u001b[38;5;66;03m# 2 слоя\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mlayers\u001b[39m\u001b[33m\"\u001b[39m: [{\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m512\u001b[39m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m256\u001b[39m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m128\u001b[39m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m64\u001b[39m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m10\u001b[39m}]}  \u001b[38;5;66;03m# 7 слоев\u001b[39;00m\n\u001b[32m     17\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VsCODE Project/Ml_practic/Lessons_3/HW/datasets.py:46\u001b[39m, in \u001b[36mget_mnist_loaders\u001b[39m\u001b[34m(batch_size)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_mnist_loaders\u001b[39m(batch_size=\u001b[32m64\u001b[39m):\n\u001b[32m     41\u001b[39m     transform = transforms.Compose([\n\u001b[32m     42\u001b[39m         transforms.ToTensor(),\n\u001b[32m     43\u001b[39m         transforms.Normalize((\u001b[32m0.1307\u001b[39m,), (\u001b[32m0.3081\u001b[39m,))\n\u001b[32m     44\u001b[39m     ])\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     train_dataset = \u001b[43mMNISTDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     test_dataset = MNISTDataset(train=\u001b[38;5;28;01mFalse\u001b[39;00m, transform=transform)\n\u001b[32m     49\u001b[39m     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VsCODE Project/Ml_practic/Lessons_3/HW/datasets.py:9\u001b[39m, in \u001b[36mMNISTDataset.__init__\u001b[39m\u001b[34m(self, train, transform)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, train=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m      8\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28mself\u001b[39m.dataset = \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VsCODE Project/Ml_practic/env/lib/python3.12/site-packages/torchvision/datasets/mnist.py:100\u001b[39m, in \u001b[36mMNIST.__init__\u001b[39m\u001b[34m(self, root, train, transform, target_transform, download)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_exists():\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataset not found. You can use download=True to download it\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VsCODE Project/Ml_practic/env/lib/python3.12/site-packages/torchvision/datasets/mnist.py:197\u001b[39m, in \u001b[36mMNIST.download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mirror, err \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.mirrors, errors):\n\u001b[32m    196\u001b[39m     s += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTried \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmirror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(err)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(s)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error downloading train-images-idx3-ubyte.gz:\nTried https://ossci-datasets.s3.amazonaws.com/mnist/, got:\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>\nTried http://yann.lecun.com/exdb/mnist/, got:\nHTTP Error 404: Not Found\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datasets import get_mnist_loaders\n",
    "from models import FullyConnectedModel\n",
    "from trainer import train_model\n",
    "from utils import plot_training_history\n",
    "\n",
    "# Получаем данные MNIST\n",
    "train_loader, test_loader = get_mnist_loaders(batch_size=64)\n",
    "\n",
    "# Список конфигураций для разных моделей\n",
    "configs = [\n",
    "    {\"layers\": [{\"type\": \"linear\", \"size\": 10}]},  # 1 слой\n",
    "    {\"layers\": [{\"type\": \"linear\", \"size\": 512}, {\"type\": \"relu\"}, {\"type\": \"linear\", \"size\": 10}]},  # 2 слоя\n",
    "    {\"layers\": [{\"type\": \"linear\", \"size\": 512}, {\"type\": \"relu\"}, {\"type\": \"linear\", \"size\": 256}, {\"type\": \"relu\"}, {\"type\": \"linear\", \"size\": 10}]},  # 3 слоя\n",
    "    {\"layers\": [{\"type\": \"linear\", \"size\": 512}, {\"type\": \"relu\"}, {\"type\": \"linear\", \"size\": 256}, {\"type\": \"relu\"}, {\"type\": \"linear\", \"size\": 128}, {\"type\": \"relu\"}, {\"type\": \"linear\", \"size\": 10}]},  # 5 слоев\n",
    "    {\"layers\": [{\"type\": \"linear\", \"size\": 512}, {\"type\": \"relu\"}, {\"type\": \"linear\", \"size\": 256}, {\"type\": \"relu\"}, {\"type\": \"linear\", \"size\": 128}, {\"type\": \"relu\"}, {\"type\": \"linear\", \"size\": 64}, {\"type\": \"relu\"}, {\"type\": \"linear\", \"size\": 10}]}  # 7 слоев\n",
    "]\n",
    "\n",
    "# Обучение и анализ каждой модели\n",
    "for i, config in enumerate(configs):\n",
    "    print(f\"Training model {i + 1}\")\n",
    "    \n",
    "    model = FullyConnectedModel(layers=config['layers']).to(device)\n",
    "\n",
    "    start_time = time.time()  # Засекаем время начала\n",
    "\n",
    "    history = train_model(model, train_loader, test_loader, epochs=5, device=str(device))\n",
    "\n",
    "    end_time = time.time()  # Засекаем время окончания\n",
    "    training_time = end_time - start_time  # Время обучения\n",
    "\n",
    "    print(f\"Training time for model {i + 1}: {training_time:.2f} seconds\")\n",
    "\n",
    "    # Визуализируем кривые обучения\n",
    "    plot_training_history(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
